For the **Web Scraping and Text Analysis Project**, I applied several essential Python programming skills to accomplish the tasks of automating article extraction, analyzing textual content, and delivering actionable insights.

The first skill applied was **web scraping** using the `requests` and `BeautifulSoup` libraries. I developed a Python script that sends HTTP requests to a list of URLs and efficiently retrieves the article content from HTML pages. This required understanding HTML structures and leveraging the parsing capabilities of BeautifulSoup to extract only the relevant parts of the webpage, such as the article titles and body text, while excluding unwanted elements like headers, footers, and advertisements.

Next, I applied **natural language processing (NLP)** using the `nltk` and `TextBlob` libraries. With NLTK, I tokenized the text into words and sentences, allowing for more granular analysis. I also implemented methods to count syllables, calculate sentence lengths, and identify complex words. The TextBlob library helped with sentiment analysis, calculating polarity and subjectivity scores for each article. This step of the project utilized text preprocessing techniques to handle real-world language data and ensure accurate results.

Additionally, I applied **data manipulation** skills using `pandas`. The project involved structuring the results of the text analysis into a pandas DataFrame and exporting it to an Excel file. This ensured the data was cleanly organized and accessible for future use.

Finally, **problem-solving and debugging skills** were crucial throughout the project. I had to address issues such as handling network errors, dealing with inconsistent HTML structures, and refining the logic for extracting and analyzing text.

By combining web scraping, NLP, and data manipulation techniques, I successfully automated the extraction and analysis of article content, showcasing how Python can be applied to real-world data processing tasks.
